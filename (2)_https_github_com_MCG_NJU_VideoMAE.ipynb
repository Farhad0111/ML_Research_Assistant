{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation\n",
        "\n",
        "**1. Example PyTorch Function and its TensorFlow Translation**"
      ],
      "metadata": {
        "id": "0lzsmYSUBUvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (PyTorch): Applies a PyTorch operation on the input tensor.\n",
        "def example_function(input_tensor):\n",
        "    processed_tensor = some_pytorch_operation(input_tensor)\n",
        "    return processed_tensor\n",
        "\n",
        "# (TensorFlow): Applies a TensorFlow operation on the input tensor.\n",
        "def example_function(input_tensor):\n",
        "    processed_tensor = some_tensorflow_operation(input_tensor)\n",
        "    return processed_tensor"
      ],
      "metadata": {
        "id": "ER7nAcG5BW4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Model Summary Validation**"
      ],
      "metadata": {
        "id": "rWuiVEEGBXGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Example PyTorch Model\n",
        "class ExampleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleModel, self).__init__()\n",
        "        self.layer = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "# Create the PyTorch model\n",
        "pytorch_model = ExampleModel()\n",
        "# Dummy input tensor for demonstration\n",
        "image_tensor = torch.rand((1, 10))\n",
        "# Forward pass through the PyTorch model\n",
        "pytorch_output = pytorch_model(image_tensor)\n",
        "\n",
        "# Example TensorFlow Model\n",
        "class ExampleTFModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ExampleTFModel, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)\n",
        "\n",
        "# Create the TensorFlow model\n",
        "tf_model = ExampleTFModel()\n",
        "# Convert the input tensor to TensorFlow\n",
        "image_tensor_tf = tf.convert_to_tensor(image_tensor.numpy())\n",
        "# Forward pass through the TensorFlow model\n",
        "tf_output = tf_model(image_tensor_tf)\n",
        "\n",
        "# Compare outputs\n",
        "print(\"PyTorch Output:\", pytorch_output.detach().numpy())\n",
        "print(\"TensorFlow Output:\", tf_output.numpy())\n",
        "#assert np.allclose(pytorch_output.detach().numpy(), tf_output.numpy(), atol=1e-6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "246QIbMVBh4Y",
        "outputId": "e07cf93b-12b0-4572-8b4f-7230df8a4b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Output: [[ 0.8336215  -0.28840205  0.20495868 -0.11333968  0.5369717  -0.34053382\n",
            "   0.2547655  -0.74007785 -0.36855108 -0.44472748]]\n",
            "TensorFlow Output: [[-0.28420705  0.00129738  0.60954744  0.380406   -0.6129231   0.37010044\n",
            "   0.7804242  -0.18147932 -0.5602173   0.3658894 ]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import torch\\nfrom torchsummary import summary\\nfrom models import create_model  # Assuming create_model is a function that initializes the model\\n\\nmodel = create_model('model_name')  # Replace with actual model initialization\\nsummary(model, input_size=(3, 224, 224))\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The outputs from PyTorch and TensorFlow models are different, indicating that while the models have similar structures, they produce different results due to differences in initialization and internal computation.\n",
        "\n",
        "Additionally, it imports `torchsummary` and shows a brief example of using `summary` to print a model's architecture and parameters for a given input size."
      ],
      "metadata": {
        "id": "mTW6Z_bkD74n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow Model Summary\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# Example TensorFlow model creation\n",
        "def create_tf_model():\n",
        "    inputs = Input(shape=(224, 224, 3))  # Adjust input shape as needed\n",
        "    x = Dense(10)(inputs)\n",
        "    outputs = Dense(1)(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = create_tf_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "88iQ9Xw0Bh6_",
        "outputId": "c26cc090-d67a-404e-bea3-52b038811222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │              \u001b[38;5;34m40\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m11\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51\u001b[0m (204.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> (204.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51\u001b[0m (204.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> (204.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model \"functional_13\" consists of the following layers and parameters:\n",
        "\n",
        "- **Input Layer:** Takes inputs of shape (224, 224, 3).\n",
        "- **Dense Layer 1:** Outputs a shape of (224, 224, 10) with 40 parameters.\n",
        "- **Dense Layer 2:** Outputs a shape of (224, 224, 1) with 11 parameters.\n",
        "\n",
        "The total number of parameters in the model is 51, all of which are trainable. There are no non-trainable parameters."
      ],
      "metadata": {
        "id": "1sCR7uUOE3-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Import PyTorch Pretrained Weights into TensorFlow**"
      ],
      "metadata": {
        "id": "DfRyPsIFBtsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PyTorch model with a single linear layer, creates an instance of the model, and saves its weights to a file named `model_weights.pth`."
      ],
      "metadata": {
        "id": "EWXjHN2EGjI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example PyTorch Model\n",
        "class ExampleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleModel, self).__init__()\n",
        "        self.layer = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "# Create and save the PyTorch model weights\n",
        "pytorch_model = ExampleModel()\n",
        "torch.save(pytorch_model.state_dict(), '/content/model_weights.pth')"
      ],
      "metadata": {
        "id": "HLKKfb_1Bt5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "599aeb02-4404-41c0-9fda-6d74a70112a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"torch.save(model.state_dict(), '/content/model_weights.pth')\\n\\n# TensorFlow - Load weights\\nimport numpy as np\\n\\ndef load_weights(tf_model, pytorch_weights_path):\\n    import torch\\n\\n    pytorch_weights = torch.load(pytorch_weights_path)\\n    for layer in tf_model.layers:\\n        if layer.name in pytorch_weights:\\n            layer_weights = pytorch_weights[layer.name]\\n            layer.set_weights([np.array(w) for w in layer_weights])\\n    return tf_model\\n\\nmodel = create_tf_model()\\nmodel = load_weights(model, '/content/model_weights.pth')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Example TensorFlow Model\n",
        "class ExampleTFModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ExampleTFModel, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)\n",
        "\n",
        "# Create TensorFlow model\n",
        "tf_model = ExampleTFModel()\n",
        "\n",
        "# Define a function to load PyTorch weights into TensorFlow model\n",
        "def load_weights(tf_model, pytorch_weights_path):\n",
        "    import torch\n",
        "\n",
        "    pytorch_weights = torch.load(pytorch_weights_path)\n",
        "    for layer in tf_model.layers:\n",
        "        layer_name = layer.name\n",
        "        if layer_name in pytorch_weights:\n",
        "            layer_weights = pytorch_weights[layer_name]\n",
        "            layer.set_weights([np.array(layer_weights['weight'].T), np.array(layer_weights['bias'])])\n",
        "    return tf_model\n",
        "\n",
        "# Load weights\n",
        "tf_model = load_weights(tf_model, 'model_weights.pth')\n",
        "\n",
        "# Verify by comparing outputs\n",
        "input_tensor = tf.random.uniform((1, 10))\n",
        "pytorch_model.eval()\n",
        "with torch.no_grad():\n",
        "    pytorch_output = pytorch_model(torch.tensor(input_tensor.numpy()))\n",
        "\n",
        "tf_output = tf_model(input_tensor)\n",
        "print(\"PyTorch Output:\", pytorch_output.numpy())\n",
        "print(\"TensorFlow Output:\", tf_output.numpy())\n",
        "#assert np.allclose(pytorch_output.numpy(), tf_output.numpy(), atol=1e-6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X715EQ-ScMcI",
        "outputId": "27164068-03bb-4630-8593-303c2019120d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Output: [[-0.40456718 -0.5836284  -0.48633805  0.90750945  0.20729594 -0.15089826\n",
            "   0.21110322 -0.3761352   0.17943528 -0.27408388]]\n",
            "TensorFlow Output: [[-0.6813714  -0.84213865  0.05494381 -0.6590186   0.31856507 -0.14267662\n",
            "  -0.5170326  -0.1786538  -0.04102371  0.50675774]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TensorFlow model and provides a function to load PyTorch model weights into it. After loading the weights, it verifies the outputs of both models with the same input, showing that the outputs differ."
      ],
      "metadata": {
        "id": "wzcqtNVJHOk4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Sanity Check with Inference**"
      ],
      "metadata": {
        "id": "hzTzce4pB2Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_image(image_path, target_size=(224, 224)):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = image.resize(target_size)\n",
        "    #Normalization:\n",
        "    image = np.array(image).astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
        "    image = (image - 0.5) / 0.5  # Normalize to [-1, 1] for compatibility with many pretrained models\n",
        "    return image\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = '/content/8ce02c42cc4d78efa28d74b28875c858.png'\n",
        "image = load_image(image_path)\n",
        "\n",
        "# PyTorch Inference\n",
        "image_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0)  # Convert to CxHxW format and add batch dimension\n",
        "\n",
        "# TensorFlow Inference\n",
        "image_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "image_tensor = tf.expand_dims(image_tensor, axis=0)  # Add batch dimension\n"
      ],
      "metadata": {
        "id": "RrXzS6nzBh-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bd637180-e13c-464e-d28d-47bb4a87b42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tf_output = model(image_tensor)\\ntf_output = tf_output.numpy()\\n\\n# Compare the outputs\\nassert np.allclose(pytorch_output, tf_output, atol=1e-6), \"Outputs are not close!\"\\nprint(\"Outputs are close!\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Selective Translation Example**"
      ],
      "metadata": {
        "id": "N8Qau3aeB856"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch - train.py\n",
        "def train(model, dataloader, optimizer):\n",
        "    model.train()\n",
        "    for data in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        #Computes the loss between the model's output and the target labels. (Note: target should be part of data in practice, but is shown here as a separate variable for simplicity.)\n",
        "        loss = compute_loss(output, target)\n",
        "        loss.backward()\n",
        "        #Updates the model's parameters using the calculated gradients.\n",
        "        optimizer.step()\n",
        "\n",
        "# TensorFlow - train.py\n",
        "def train(model, dataset, optimizer):\n",
        "    for data in dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = model(data)\n",
        "            loss = compute_loss(output, target)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "metadata": {
        "id": "nFKWmh_EB9Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The extracted cells provide a good starting point, but the code snippets are incomplete. To make the translation runnable, need to integrate and complete the code. Let's proceed by writing a complete example with PyTorch and its corresponding TensorFlow translation, including the necessary imports, model definitions, training functions, and validation steps.\n",
        "\n",
        "### Complete Translation Example\n",
        "\n",
        "**1. PyTorch Implementation**"
      ],
      "metadata": {
        "id": "crsvNVNoCEjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "# Example PyTorch Model\n",
        "class ExampleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleModel, self).__init__()\n",
        "        self.layer = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "# Create and summarize the model\n",
        "model = ExampleModel()\n",
        "summary(model, input_size=(1, 10))\n",
        "\n",
        "# Training function\n",
        "def train(model, dataloader, optimizer):\n",
        "    model.train()\n",
        "    for data, target in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = nn.MSELoss()(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Save model weights\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIKLIFkYCLWX",
        "outputId": "a80779e9-d64c-4a97-a06f-9c53fb19848a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 1, 10]             110\n",
            "================================================================\n",
            "Total params: 110\n",
            "Trainable params: 110\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output is a summary of a simple neural network model, likely generated using a tool like `torchsummary` in PyTorch.\n",
        "\n",
        "1. **Layer (type):**\n",
        "   - **Linear-1:** Indicates that this is the first layer in the network, and it is a linear (fully connected) layer.\n",
        "\n",
        "2. **Output Shape:**\n",
        "   - **[-1, 1, 10]:**\n",
        "     - **-1:** Represents the batch size, which is flexible and determined at runtime.\n",
        "     - **1:** Indicates the batch dimension size, meaning the output for each input sample is a tensor with a batch size of 1.\n",
        "     - **10:** Indicates that the output dimension of this layer is 10.\n",
        "\n",
        "3. **Param #:**\n",
        "   - **110:** Indicates the number of parameters (weights and biases) in this layer.\n",
        "     - For a linear layer, the number of parameters is calculated as `(input_features * output_features) + output_features` (biases).\n",
        "     - Assuming input features are 10: \\( (10 \\times 10) + 10 = 110 \\).\n",
        "\n",
        " This model is extremely simple, with only one linear layer containing 110 parameters. The memory usage is minimal, and all parameters are trainable. This kind of model might be used for a basic demonstration or a very simple task."
      ],
      "metadata": {
        "id": "NguRXVg9L8vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. TensorFlow Implementation**"
      ],
      "metadata": {
        "id": "TnV6iJT7CMaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "# Example TensorFlow Model\n",
        "class ExampleModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ExampleModel, self).__init__()\n",
        "        self.layer = Dense(10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.layer(inputs)\n",
        "\n",
        "# Create and summarize the model\n",
        "def create_tf_model():\n",
        "    inputs = Input(shape=(10,))\n",
        "    outputs = ExampleModel()(inputs)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = create_tf_model()\n",
        "model.summary()\n",
        "\n",
        "# Training function\n",
        "def train(model, dataset, optimizer):\n",
        "    for data, target in dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = model(data)\n",
        "            loss = tf.keras.losses.mean_squared_error(target, output)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "# Load PyTorch weights into TensorFlow model\n",
        "def load_weights(tf_model, pytorch_weights_path):\n",
        "    import torch\n",
        "    import numpy as np\n",
        "\n",
        "    pytorch_weights = torch.load(pytorch_weights_path)\n",
        "    for layer in tf_model.layers:\n",
        "        if layer.name in pytorch_weights:\n",
        "            layer_weights = pytorch_weights[layer.name]\n",
        "            layer.set_weights([np.array(w) for w in layer_weights])\n",
        "    return tf_model\n",
        "\n",
        "model = load_weights(model, 'model_weights.pth')\n",
        "\n",
        "# Sanity check with inference\n",
        "def load_image(image_path):\n",
        "    # Dummy function to load and preprocess an image\n",
        "    image = tf.random.normal((224, 224, 3))\n",
        "    return image\n",
        "\n",
        "image = load_image('sample.jpg')\n",
        "image_tensor = tf.expand_dims(image, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "e2zfDkKsCTa_",
        "outputId": "8df60be3-9bfe-4390-bfbb-d68ae3864f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_15 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ example_model_13 (\u001b[38;5;33mExampleModel\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ example_model_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ExampleModel</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110\u001b[0m (440.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> (440.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110\u001b[0m (440.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> (440.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"pytorch_model = ExampleModel()\\npytorch_model.load_state_dict(torch.load('model_weights.pth'))\\npytorch_output = pytorch_model(torch.tensor(image_tensor.numpy()))\\n\\ntf_output = model(image_tensor)\\n\\n# Compare outputs\\nassert np.allclose(pytorch_output.detach().numpy(), tf_output.numpy(), atol=1e-6)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This summary describes a simple neural network model with the following details:\n",
        "\n",
        "1. **Model Name:** `functional_14`\n",
        "\n",
        "2. **Layers:**\n",
        "   - **InputLayer (`input_layer_15`):**\n",
        "     - **Output Shape:** `(None, 10)`\n",
        "     - **Parameters:** `0`\n",
        "     - The input layer takes inputs of shape 10, with `None` indicating that the batch size can be of any size.\n",
        "   - **ExampleModel (`example_model_13`):**\n",
        "     - **Output Shape:** `(None, 10)`\n",
        "     - **Parameters:** `110`\n",
        "     - This is a linear layer that outputs a tensor of shape 10. It has 110 parameters (weights and biases).\n",
        "\n",
        "3. **Parameter Summary:**\n",
        "   - **Total Parameters:** `110` (440.00 B)\n",
        "   - **Trainable Parameters:** `110` (440.00 B)\n",
        "   - **Non-trainable Parameters:** `0` (0.00 B)\n",
        "\n",
        "   \n",
        "This model consists of an input layer and a single linear layer with 110 trainable parameters. All parameters are trainable, and the model has a very minimal memory footprint."
      ],
      "metadata": {
        "id": "PdaxvNvOM4sZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Steps to Run\n",
        "\n",
        "1. **PyTorch**:\n",
        "   - Define the model.\n",
        "   - Print the model summary.\n",
        "   - Define and run the training function.\n",
        "   - Save the model weights.\n",
        "\n",
        "2. **TensorFlow**:\n",
        "   - Define the model.\n",
        "   - Print the model summary.\n",
        "   - Define and run the training function.\n",
        "   - Load PyTorch weights into the TensorFlow model.\n",
        "   - Perform a sanity check with an inference.\n",
        "\n",
        "By following these steps, we can ensure the successful translation of the PyTorch repository to TensorFlow, making the TensorFlow version runnable without any issues. Let's proceed to implement and run these steps in the provided notebook context.\n",
        "\n",
        "The `torchsummary` module is not available in this environment. We can proceed without it by manually printing the model summary using the model's `state_dict()` and `parameters()` methods. Let's implement the PyTorch part first:\n",
        "\n",
        "### PyTorch Implementation\n",
        "\n",
        "1. **Model Definition and Summary**\n",
        "2. **Training Function**\n",
        "3. **Save Model Weights**"
      ],
      "metadata": {
        "id": "AaBgwqKYCUzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Example PyTorch Model\n",
        "class ExampleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleModel, self).__init__()\n",
        "        self.layer = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "# Create the model\n",
        "pytorch_model = ExampleModel()\n",
        "\n",
        "# Print model summary\n",
        "print(\"PyTorch Model Summary:\")\n",
        "for name, param in pytorch_model.named_parameters():\n",
        "    print(f\"{name}: {param.shape}\")\n",
        "\n",
        "# Save model weights\n",
        "torch.save(pytorch_model.state_dict(), '/content/model_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7M5ej2ICYyd",
        "outputId": "6847aab6-d11c-4969-8616-ad9f7fa1bb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Model Summary:\n",
            "layer.weight: torch.Size([10, 10])\n",
            "layer.bias: torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The linear layer has a weight matrix of shape `[10, 10]` and a bias vector of shape `[10]`, indicating it maps 10 input features to 10 output features."
      ],
      "metadata": {
        "id": "PefLRhBZNb7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's move on to the TensorFlow implementation:\n",
        "\n",
        "### TensorFlow Implementation\n",
        "\n",
        "1. **Model Definition and Summary**\n",
        "2. **Load PyTorch Weights**\n",
        "3. **Sanity Check with Inference**"
      ],
      "metadata": {
        "id": "o14HHiZgCfGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Example TensorFlow Model\n",
        "class ExampleTFModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ExampleTFModel, self).__init__()\n",
        "        self.layer = tf.keras.layers.Dense(10, use_bias=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.layer(inputs)\n",
        "\n",
        "# Create the TensorFlow model\n",
        "def create_tf_model():\n",
        "    inputs = tf.keras.Input(shape=(10,))\n",
        "    outputs = ExampleTFModel()(inputs)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "tf_model = create_tf_model()\n",
        "print(\"TensorFlow Model Summary:\")\n",
        "tf_model.summary()\n",
        "\n",
        "# Load PyTorch weights into TensorFlow model\n",
        "def load_weights(tf_model, pytorch_weights_path):\n",
        "    import torch\n",
        "\n",
        "    pytorch_weights = torch.load(pytorch_weights_path)\n",
        "\n",
        "    # Convert PyTorch weight tensors to NumPy arrays and transpose them\n",
        "    dense_weights = pytorch_weights['layer.weight'].T.numpy()\n",
        "    dense_bias = pytorch_weights['layer.bias'].numpy()\n",
        "\n",
        "    # Set weights to TensorFlow model\n",
        "    tf_model.layers[1].set_weights([dense_weights, dense_bias])\n",
        "\n",
        "    return tf_model\n",
        "\n",
        "tf_model = load_weights(tf_model, '/content/model_weights.pth')\n",
        "\n",
        "# Sanity check with inference\n",
        "def load_image(image_path):\n",
        "    # Dummy function to load and preprocess an image\n",
        "    return tf.random.normal((10,))\n",
        "\n",
        "image = load_image('/content/8ce02c42cc4d78efa28d74b28875c858.png')\n",
        "image_tensor = tf.expand_dims(image, axis=0)\n",
        "\n",
        "pytorch_model.eval()\n",
        "with torch.no_grad():\n",
        "    pytorch_output = pytorch_model(torch.tensor(image_tensor.numpy()))\n",
        "\n",
        "tf_output = tf_model(image_tensor)\n",
        "\n",
        "# Compare outputs\n",
        "print(\"PyTorch Output:\", pytorch_output.numpy())\n",
        "print(\"TensorFlow Output:\", tf_output.numpy())\n",
        "assert np.allclose(pytorch_output.numpy(), tf_output.numpy(), atol=1e-6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "pQJkgvPTdWTi",
        "outputId": "1e03d53d-6ec4-45c4-9358-b275d131cfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ example_tf_model_4 (\u001b[38;5;33mExampleTFModel\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ example_tf_model_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ExampleTFModel</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110\u001b[0m (440.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> (440.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110\u001b[0m (440.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> (440.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Output: [[ 1.5413572  -0.5877558   0.60559803  0.09567821 -0.20602801 -0.5365215\n",
            "   0.4888842  -0.1711604   0.3136797  -0.42868203]]\n",
            "TensorFlow Output: [[ 1.5413572  -0.58775586  0.60559803  0.09567821 -0.20602801 -0.5365215\n",
            "   0.48888427 -0.1711604   0.31367967 -0.428682  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TensorFlow model consists of an input layer and a single dense layer with 110 trainable parameters. Both the PyTorch and TensorFlow models produce nearly identical outputs, indicating that the model weights have been successfully transferred and the models behave equivalently."
      ],
      "metadata": {
        "id": "h4mG2TAuOEls"
      }
    }
  ]
}