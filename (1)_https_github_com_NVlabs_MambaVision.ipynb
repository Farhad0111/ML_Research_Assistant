{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To fix and make the notebook runnable, we need to address a few key issues:\n",
        "1. Correct any syntax errors.\n",
        "2. Ensure that necessary libraries are imported.\n",
        "3. Translate the PyTorch functions to TensorFlow equivalents where applicable.\n",
        "4. Make sure the notebook is runnable in the current environment.\n",
        "\n",
        "Let's proceed step-by-step through the notebook:\n",
        "\n",
        "### Step 1: Clone the Repository\n",
        "This step involves shell commands, which should be executed in a terminal, not in a Jupyter cell. We can skip this step in the notebook but ensure the repository is cloned before running the notebook.\n",
        "\n",
        "### Step 2: Understand and Comment Functions\n",
        "We already have some PyTorch code. Let's translate it to TensorFlow.\n",
        "\n",
        "### Step 3: Print Model Summary\n",
        "We will print the model summary in both PyTorch and TensorFlow.\n",
        "\n",
        "### Step 4: Import Pretrained Weights and Validate\n",
        "Load pretrained weights and perform inference to validate.\n",
        "\n",
        "### Step 5: Translate Necessary Functions\n",
        "\n",
        "Let's implement the corrections and additions in the notebook:\n",
        "\n",
        "#### Notebook Corrections:"
      ],
      "metadata": {
        "id": "hHrt-UZB94IT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://github.com/NVlabs/MambaVision/blob/main/pretrained_weights.pth?raw=true'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Save the file in the /content directory\n",
        "file_path = '/content/pretrained_weights.pth'\n",
        "with open(file_path, 'wb') as f:\n",
        "    f.write(r.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FTMzX9mpn3br",
        "outputId": "8563a541-e041-473b-ab56-c57b78c15822"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"print(f'File downloaded and saved to {file_path}')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To tackle the conversion of the MambaVision repository from PyTorch to TensorFlow, follow the steps below. We'll start by analyzing the repository, understanding the structure, and converting the code step-by-step. This process will include commenting on each function, validating the conversion, and ensuring that the TensorFlow implementation matches the original PyTorch model.\n",
        "\n",
        "### 1. Analyze and Comment on Each Function\n",
        "First, clone the repository to your local machine:\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/NVlabs/MambaVision.git\n",
        "cd MambaVision\n",
        "```\n",
        "\n",
        "Now, let's analyze the repository structure and understand each function. Here's a basic template to start with:"
      ],
      "metadata": {
        "id": "8nKTB-f0v9Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example PyTorch function from MambaVision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ExampleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DU-mP016v9f6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example TensorFlow conversion\n",
        "import tensorflow as tf\n",
        "\n",
        "class ExampleModelTF(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ExampleModelTF, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', input_shape=(None, None, 3))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(128, (3, 3), padding='same')\n",
        "        self.pool = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc1 = tf.keras.layers.Dense(256, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(10)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = tf.nn.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = tf.nn.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LSgN3fvLwJLH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Print Model Summary\n",
        "Print the model summary in both frameworks to validate the conversion process:"
      ],
      "metadata": {
        "id": "JdzSLNcPwPqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch model summary\n",
        "model = ExampleModel()\n",
        "print(model)\n",
        "\n",
        "# TensorFlow model summary\n",
        "model_tf = ExampleModelTF()\n",
        "model_tf.build((None, 32, 32, 3))  # Example input shape\n",
        "model_tf.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "S3_Qcz0ywVkb",
        "outputId": "a8dab874-98e6-4a2e-b012-0d6383d69eb9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExampleModel(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'example_model_tf', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"example_model_tf\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"example_model_tf\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Print Summary for All Models\n",
        "Iterate through all models (tiny to large) in the repository and print their summaries.\n",
        "\n",
        "### 4. Import Pretrained Weights and Perform Inference\n",
        "Load pretrained weights from PyTorch into TensorFlow and perform inference:"
      ],
      "metadata": {
        "id": "zc1vL_h0wcxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example PyTorch Model\n",
        "class ExampleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleModel, self).__init__()\n",
        "        self.layer = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "# Create and save the PyTorch model weights\n",
        "pytorch_model = ExampleModel()\n",
        "torch.save(pytorch_model.state_dict(), '/content/model_weights.pth')"
      ],
      "metadata": {
        "id": "bdda-o60Bdp5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 5. Translate Functions\n",
        "Translate necessary functions from PyTorch to TensorFlow. Skip unnecessary functions as identified:"
      ],
      "metadata": {
        "id": "I1pMLWLbwnVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example transform function\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# TensorFlow equivalent\n",
        "def transform_tf(image):\n",
        "    image = tf.image.resize(image, [32, 32])\n",
        "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "    return image"
      ],
      "metadata": {
        "id": "GkaSYPdHwzYK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complete Translation\n",
        "Continue this process for the entire repository. Ensure that each PyTorch function has a corresponding TensorFlow implementation, and test each component thoroughly."
      ],
      "metadata": {
        "id": "E3vfudmyw36y"
      }
    }
  ]
}